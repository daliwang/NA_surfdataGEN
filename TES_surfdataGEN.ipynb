{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb811ce-bf60-4fe3-996f-e69fde1ba284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(769, 1705) (769, 1705) (558794,) (558794,) 558794\n",
      "Checking on varibale: mxsoil_color dimensions: ()\n",
      "Copying variable: mxsoil_color takes  0.0006653180000029124\n",
      "0\n",
      "Checking on varibale: mxsoil_order dimensions: ()\n",
      "Copying variable: mxsoil_order takes  0.0005335300000055554\n",
      "0\n",
      "Checking on varibale: SOIL_COLOR dimensions: ('lsmlat', 'lsmlon')\n",
      "Working on varibale: SOIL_COLOR dimensions: ('lsmlat', 'lsmlon')\n",
      "Generating variable: SOIL_COLOR takes  0.2681133129999935\n",
      "1\n",
      "Checking on varibale: SOIL_ORDER dimensions: ('lsmlat', 'lsmlon')\n",
      "Working on varibale: SOIL_ORDER dimensions: ('lsmlat', 'lsmlon')\n",
      "Generating variable: SOIL_ORDER takes  0.2730195880000039\n",
      "2\n",
      "Checking on varibale: PCT_SAND dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n",
      "Working on varibale: PCT_SAND dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n",
      "Generating variable: PCT_SAND takes  2.765440189000003\n",
      "12\n",
      "Checking on varibale: PCT_CLAY dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n",
      "Working on varibale: PCT_CLAY dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n",
      "Generating variable: PCT_CLAY takes  2.7601693869999977\n",
      "22\n",
      "Checking on varibale: ORGANIC dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n",
      "Working on varibale: ORGANIC dimensions: ('nlevsoi', 'lsmlat', 'lsmlon')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 385\u001b[0m\n\u001b[1;32m    382\u001b[0m     src\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    383\u001b[0m     dst\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 385\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 303\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m source \u001b[38;5;241m=\u001b[39m src[name][index,:,:]\n\u001b[1;32m    302\u001b[0m o_data \u001b[38;5;241m=\u001b[39m source[points_in_daymet_land[\u001b[38;5;241m4\u001b[39m][:],points_in_daymet_land[\u001b[38;5;241m5\u001b[39m][:]]\n\u001b[0;32m--> 303\u001b[0m f_data1 \u001b[38;5;241m=\u001b[39m \u001b[43mgriddata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_lon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miMethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (domain_type \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# Assign the interpolated data\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     dst[name][index,\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(f_data1)\n",
      "File \u001b[0;32m~/PyEnv/lib/python3.11/site-packages/scipy/interpolate/_ndgriddata.py:321\u001b[0m, in \u001b[0;36mgriddata\u001b[0;34m(points, values, xi, method, fill_value, rescale)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    320\u001b[0m     ip \u001b[38;5;241m=\u001b[39m NearestNDInterpolator(points, values, rescale\u001b[38;5;241m=\u001b[39mrescale)\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    323\u001b[0m     ip \u001b[38;5;241m=\u001b[39m LinearNDInterpolator(points, values, fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    324\u001b[0m                               rescale\u001b[38;5;241m=\u001b[39mrescale)\n",
      "File \u001b[0;32m~/PyEnv/lib/python3.11/site-packages/scipy/interpolate/_ndgriddata.py:144\u001b[0m, in \u001b[0;36mNearestNDInterpolator.__call__\u001b[0;34m(self, *args, **query_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m flattened_shape \u001b[38;5;241m=\u001b[39m xi_flat\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# if distance_upper_bound is set to not be infinite,\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# then we need to consider the case where cKDtree\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# does not find any points within distance_upper_bound to return.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# It marks those points as having infinte distance, which is what will be used\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# below to mask the array and return only the points that were deemed\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# to have a close enough neighbor to return something useful.\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m dist, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquery_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m valid_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misfinite(dist)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# create a holder interp_values array and fill with nans.\u001b[39;00m\n",
      "File \u001b[0;32m_ckdtree.pyx:830\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/baseline/anaconda3/23.10/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:195\u001b[0m, in \u001b[0;36m_reshape_dispatcher\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Take elements from an array along an axis.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m           [5, 7]])\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m, indices, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reshape_dispatcher\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# not deprecated --- copy if necessary, view otherwise\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import netCDF4 as nc\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from time import process_time\n",
    "#from memory_profiler import profile\n",
    "from pyproj import Proj\n",
    "from pyproj import Transformer\n",
    "from pyproj import CRS\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    args = sys.argv[1:]\n",
    "    user_option = args[0]\n",
    "    domain_type = args[1]\n",
    "\n",
    "    if  len(sys.argv) != 2 or sys.argv[1] == '--help':  # sys.argv includes the script name as the first argument\n",
    "        print(\"Example use: python NA_surfdataGEN.py <domain_option>\")\n",
    "        print(\" The code generate 2D NA surfdata from 0.5x0.5 degree globla surfdata\")              \n",
    "        exit(0)\n",
    "    '''\n",
    "    domain_type = '2'\n",
    "    \n",
    "    if (domain_type == '1'):\n",
    "        output_file = \"surfdata.Daymet_GSWP3_TESSFA.4km.1d.nc\"\n",
    "        \n",
    "    if (domain_type == '2'):\n",
    "        output_file = \"surfdata.Daymet_GSWP3_TESSFA.4km.2d.nc\"\n",
    "\n",
    "    # Only variables listed will be processed\n",
    "\n",
    "    # nearest neighbor:\"double\" variables\n",
    "    Variable_nearest = ['SLOPE', 'TOPO', 'PCT_GLACIER', 'PCT_LAKE', 'STD_ELEV']\n",
    "    # nearest neighbor:\"int\" variables\n",
    "    Variable_nearest += ['PFTDATA_MASK','SOIL_COLOR', 'SOIL_ORDER', 'abm']\n",
    "    # nearest neighbor:\"double\" variables (added 11/07/22023)\n",
    "    Variable_nearest += ['EF1_BTR', 'EF1_CRP', 'EF1_FDT', 'EF1_FET', 'EF1_GRS', 'EF1_SHR']\n",
    "    # nearest neighbor: \"double\" variables (added 11/10/2023)\n",
    "    Variable_nearest += ['PCT_SAND', 'PCT_CLAY','ORGANIC' ,'PCT_NAT_PFT', \n",
    "            'MONTHLY_LAI', 'MONTHLY_SAI' ,'MONTHLY_HEIGHT_TOP', 'MONTHLY_HEIGHT_BOT']\n",
    "\n",
    "    # nearest neighbor:\"int\" variables (gridcell)\n",
    "    Variable_urban_nearest = ['URBAN_REGION_ID']\n",
    "    # nearest neighbor:\"int\" variables (numurbl, gridcell)\n",
    "    Variable_urban_nearest += ['NLEV_IMPROAD' ]\n",
    "    # nearest neighbor:\"double\" variables (numurbl, gridcell)\n",
    "    Variable_urban_nearest += ['T_BUILDING_MAX', 'T_BUILDING_MIN',\n",
    "            'WIND_HGT_CANYON','WTLUNIT_ROOF','WTROAD_PERV','THICK_ROOF',\n",
    "            'THICK_WALL','PCT_URBAN','HT_ROOF','EM_IMPROAD','EM_PERROAD',\n",
    "            'EM_ROOF','EM_WALL','CANYON_HWR']\n",
    "    # nearest neighbor:\"double\" variables (nlevurb, numurbl, gridcell)\n",
    "    Variable_urban_nearest += ['TK_IMPROAD','TK_ROOF','TK_WALL', \n",
    "                                     'CV_IMPROAD', 'CV_ROOF', 'CV_WALL']\n",
    "\n",
    "    # nearest neighbor:\"double\" variables (numrad, numurbl, gridcell)\n",
    "    Variable_urban_nearest += ['ALB_IMPROAD_DIF','ALB_IMPROAD_DIR','ALB_PERROAD_DIF',\n",
    "            'ALB_PERROAD_DIR','ALB_ROOF_DIF', 'ALB_ROOF_DIR',\n",
    "            'ALB_WALL_DIF', 'ALB_WALL_DIR']\n",
    "\n",
    "    Variable_nearest += Variable_urban_nearest\n",
    "\n",
    "    # linear interpolation of \"double\" variables\n",
    "    Variable_linear = ['FMAX', 'Ws', 'ZWT0', 'binfl', 'gdp', \n",
    "                    'peatf', 'Ds', 'Dsmax', 'F0', 'LAKEDEPTH',\n",
    "                   'LANDFRAC_PFT','P3', 'PCT_NATVEG', 'PCT_WETLAND', \n",
    "                    'SECONDARY_P', 'OCCLUDED_P', 'LABILE_P']\n",
    "\n",
    "    # linear: \"double\" variables (added 11/07/22023)\n",
    "    Variable_linear += ['APATITE_P', 'PCT_CROP']\n",
    "\n",
    "    # TES domain is defined in WGS84 system, so we do not need projections\n",
    "    # But we keep them in the code for src_x, src_y\n",
    "    #Proj4: +proj=lcc +lon_0=-100 +lat_1=25 +lat_2=60 +k=1 +x_0=0 +y_0=0 +R=6378137 +f=298.257223563 +units=m  +no_defs\n",
    "    geoxy_proj_str = \"+proj=lcc +lon_0=-100 +lat_0=42.5 +lat_1=25 +lat_2=60 +x_0=0 +y_0=0 +R=6378137 +f=298.257223563 +units=m +no_defs\"\n",
    "    geoxyProj = CRS.from_proj4(geoxy_proj_str)\n",
    "    # EPSG: 4326\n",
    "    # Proj4: +proj=longlat +datum=WGS84 +no_defs\n",
    "    lonlatProj = CRS.from_epsg(4326) # in lon/lat coordinates\n",
    "    Txy2lonlat = Transformer.from_proj(geoxyProj, lonlatProj, always_xy=True)\n",
    "    Tlonlat2xy = Transformer.from_proj(lonlatProj, geoxyProj, always_xy=True)\n",
    "\n",
    "    # Open the source file\n",
    "    src = nc.Dataset('surfdata.nc', 'r')\n",
    "    # points = [y,x] coordinates for src's grid\n",
    "    src_resx = 0.5\n",
    "    src_resy = 0.5\n",
    "    src_lat = src.variables['LATIXY'][...]\n",
    "    src_lon = src.variables['LONGXY'][...]\n",
    "    src_x,src_y = Tlonlat2xy.transform(src_lon,src_lat)\n",
    "    src_lon[src_lon<0.0]=360+src_lon[src_lon<0.0]\n",
    "    \n",
    "    \n",
    "    # Create a new file      \n",
    "    if os.path.isfile(output_file):\n",
    "        # If it does, delete it\n",
    "        os.remove(output_file)\n",
    "        \n",
    "    dst = nc.Dataset(output_file, 'w')\n",
    "\n",
    "    # Copy dimensions\n",
    "    for name, dimension in src.dimensions.items():\n",
    "        dst.createDimension(\n",
    "            name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "    # Copy global attributes\n",
    "    dst.setncatts(src.__dict__)\n",
    "\n",
    "    # get the fine resolution data and the locations (lat, lon)\n",
    "    #r_daymet = nc.Dataset('clmforc.Daymet4.1km.TBOT.2014-01.nc', 'r', format='NETCDF4')\n",
    "    # TBOT data comes with TES domain information\n",
    "    # TES domain is defined in WGS84 coordinates\n",
    "    r_daymet = nc.Dataset('TES_TBOT.nc', 'r', format='NETCDF4')    \n",
    "    x_dim = r_daymet['lon']  # 1D x-axis\n",
    "    y_dim = r_daymet['lat']  # 1D y-axis\n",
    "    TBOT = r_daymet.variables['TBOT'][0,:,:]\n",
    "\n",
    "    grid_ids = np.linspace(0, len(x_dim)*len(y_dim)-1, len(x_dim)*len(y_dim), dtype=int)\n",
    "    grid_ids = grid_ids.reshape(TBOT.shape)\n",
    "    grid_xids = np.indices(grid_ids.shape)[1]\n",
    "    grid_yids = np.indices(grid_ids.shape)[0]\n",
    "\n",
    "    # setup the bool_mask and (lon, lat) mesh of the TES domain\n",
    "    bool_mask = ~np.isnan(TBOT)\n",
    "    grid_lon, grid_lat = np.meshgrid(x_dim,y_dim)\n",
    "    #lon,lat = Txy2lonlat.transform(grid_x,grid_y)\n",
    "    lon = grid_lon # save for 1D surfdata\n",
    "    lat = grid_lat # save for 1D surfdata\n",
    "\n",
    "    grid_lat = np.copy(grid_lat[bool_mask])\n",
    "    grid_lon = np.copy(grid_lon[bool_mask])\n",
    "\n",
    "    gridcells= len(grid_lat)\n",
    "\n",
    "    # masked daymet gridcell's lon/lat\n",
    "    #grid_lon,grid_lat = Txy2lonlat.transform(grid_x1,grid_y1)\n",
    "    grid_lon[grid_lon<0.0]=360+grid_lon[grid_lon<0.0]\n",
    "\n",
    "    print(TBOT.shape,bool_mask.shape, grid_lon.shape, grid_lat.shape, gridcells)\n",
    "    #del grid_x, grid_y\n",
    "\n",
    "    # prepare the data source with points_in_daymet_land\n",
    "    idxy = np.nonzero((src_lat<=max(grid_lat)+src_resy) & (src_lat>=min(grid_lat)-src_resy) & \\\n",
    "                      (src_lon<=max(grid_lon)+src_resx) & (src_lon>=min(grid_lon)-src_resx) )\n",
    "    points_in_daymet_land = {}\n",
    "    points_in_daymet_land[0] = src_x[idxy]\n",
    "    points_in_daymet_land[1] = src_y[idxy]\n",
    "    points_in_daymet_land[2] = src_lat[idxy]\n",
    "    points_in_daymet_land[3] = src_lon[idxy]\n",
    "    points_in_daymet_land[4] = idxy[0]\n",
    "    points_in_daymet_land[5] = idxy[1]\n",
    "    land_points = len(points_in_daymet_land[0])\n",
    "    points=np.zeros((land_points, 2), dtype='double')\n",
    "    points[:,0] = src_y[idxy]\n",
    "    points[:,1] = src_x[idxy]\n",
    "\n",
    "    # Create new dimensions for TES domain\n",
    "    dst.createDimension('lon', x_dim.size)\n",
    "    dst.createDimension('lat', y_dim.size)\n",
    "\n",
    "    dst_var = dst.createVariable('lon', np.float32, ('lon'))\n",
    "    dst_var.units = \"degree\"\n",
    "    dst_var.long_name = \"x coordinate of projection\"\n",
    "    dst_var.standard_name = \"x_project_coordinate\"\n",
    "    dst['lon'][...] = np.copy(x_dim)\n",
    "    dst_var = dst.createVariable('lat', np.float32, ('lat'))\n",
    "    dst_var.units = \"degree\"\n",
    "    dst_var.long_name = \"y coordinate of projection\"\n",
    "    dst_var.standard_name = \"projection_y_coordinate\"\n",
    "    dst['lat'][...] = np.copy(y_dim)\n",
    "\n",
    "    '''dst_var = dst.createVariable('lambert_conformal_conic', np.short)\n",
    "    dst_var.grid_mapping_name = \"lambert_conformal_conic\"\n",
    "    dst_var.longitude_of_central_meridian = -100.\n",
    "    dst_var.latitude_of_projection_origin = 42.5\n",
    "    dst_var.false_easting = 0.\n",
    "    dst_var.false_northing = 0.\n",
    "    dst_var.standard_parallel = 25., 60.\n",
    "    dst_var.semi_major_axis = 6378137.\n",
    "    dst_var.inverse_flattening = 298.257223563'''\n",
    "\n",
    "    if (domain_type == '1'):\n",
    "        dst_var = dst.createVariable('lon2D', np.float32, ('lat','lon'))\n",
    "        dst_var.units = \"degrees_east\"\n",
    "        dst_var.long_name = \"longitude coordinate\"\n",
    "        dst_var.standard_name = \"longitude\"\n",
    "        dst['lon2D'][...] = np.copy(lon)\n",
    "        dst_var = dst.createVariable('lat2D', np.float32, ('lat','lon'))\n",
    "        dst_var.units = \"degrees_north\"\n",
    "        dst_var.long_name = \"latitude coordinate\"\n",
    "        dst_var.standard_name = \"latitude\"\n",
    "        dst['lat2D'][...] = np.copy(lat)\n",
    "\n",
    "        dst.createDimension('gridcell', gridcells)\n",
    "        \n",
    "        dst_var = dst.createVariable('gridID', np.int32, ('gridcell'))\n",
    "        dst_var.long_name = 'gridId in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner of the domain, covering all land and ocean gridcells\" \n",
    "        dst['gridID'][...] = np.copy(grid_ids[bool_mask])\n",
    "\n",
    "        dst_var = dst.createVariable('gridXID', np.int32, ('gridcell'))\n",
    "        dst_var.long_name = 'gridId x in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner and from west to east of the domain, with gridID=gridXID+gridYID*x_dim\" \n",
    "        dst.variables['gridXID'][...] = np.copy(grid_xids[bool_mask])\n",
    "    \n",
    "        dst_var = dst.createVariable('gridYID', np.int32, ('gridcell'))\n",
    "        dst_var.long_name = 'gridId y in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner and from north to south of the domain, with gridID=gridXID+gridYID*y_dim\" \n",
    "        dst.variables['gridYID'][...] = np.copy(grid_yids[bool_mask])\n",
    "    else:\n",
    "        dst_var = dst.createVariable('gridID', np.int32, ('lat','lon'))\n",
    "        dst_var.long_name = 'gridId in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner of the domain, covering all land and ocean gridcells\" \n",
    "        dst.variables['gridID'][...] = np.copy(grid_ids)\n",
    "    \n",
    "        dst_var = dst.createVariable('gridXID', np.int32, ('lat','lon'))\n",
    "        dst_var.long_name = 'gridId x in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner and from west to east of the domain, with gridID=gridXID+gridYID*x_dim\" \n",
    "        dst.variables['gridXID'][...] = np.copy(grid_xids)\n",
    "    \n",
    "        dst_var = dst.createVariable('gridYID', np.int32, ('lat','lon'))\n",
    "        dst_var.long_name = 'gridId y in the NA domain'\n",
    "        dst_var.decription = \"start from #0 at the upper left corner and from north to south of the domain, with gridID=gridXID+gridYID*y_dim\" \n",
    "        dst.variables['gridYID'][...] = np.copy(grid_yids)\n",
    "        \n",
    "\n",
    "    count = 0 # record how may 2D layers have been processed \n",
    "\n",
    "    # Copy variables\n",
    "    for name, variable in src.variables.items():\n",
    "        start = process_time()\n",
    "        print(\"Checking on varibale: \"+ name + \" dimensions: \" + str(variable.dimensions))\n",
    "        \n",
    "        # Check if the last two dimensions are lsmlat and lsmlon\n",
    "        if (variable.dimensions[-2:] == ('lsmlat', 'lsmlon')):\n",
    "            # Determine the interpolation method\n",
    "            if name in Variable_linear:\n",
    "                iMethod = 'linear'\n",
    "            else:\n",
    "                iMethod = 'nearest'\n",
    "\n",
    "            print(\"Working on varibale: \"+ name + \" dimensions: \" + str(variable.dimensions))\n",
    "\n",
    "            # create variables with the new dimensions\n",
    "\n",
    "            if variable.datatype == np.int32:\n",
    "                fill_value = -9999  # or any other value that you want to use to represent missing data\n",
    "            else:\n",
    "                fill_value = np.nan\n",
    "\n",
    "            if (domain_type =='1'):\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions[:-2]+ ('gridcell',), fill_value = fill_value)\n",
    "            else:\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions[:-2]+ ('lat', 'lon'), fill_value = fill_value)\n",
    "                \n",
    "\t    # Copy variable attributes\n",
    "            dst[name].setncatts(src[name].__dict__)\n",
    "\n",
    "            # prepare the array for the interpolated result\n",
    "            f_data1 = np.zeros(gridcells, dtype=variable.datatype)\n",
    "\n",
    "            # original variable data (source) that need to be interpolated\n",
    "            o_data=np.zeros(land_points, dtype=variable.datatype)\n",
    "             \n",
    "            # Handle variables with two dimensions\n",
    "            if (len(variable.dimensions) == 2):\n",
    "                source = src[name][:]\n",
    "                o_data = source[points_in_daymet_land[4][:],points_in_daymet_land[5][:]]\n",
    "                f_data1 = griddata(points, o_data, (grid_lat, grid_lon), method=iMethod)\n",
    "                if name=='AREA': f_data1[...] = 16.0  # need to get the AREA value from Domain files\n",
    "                if name=='LONGXY': f_data1[...] = grid_lon\n",
    "                if name=='LATIXY': f_data1[...] = grid_lat\n",
    "                \n",
    "                if (domain_type == '1'):\n",
    "                    # Assign the interpolated data\n",
    "                    dst[name][...] = np.copy(f_data1)\n",
    "                    \n",
    "                else:\n",
    "      \n",
    "                # put the masked data back to the data (with the TES land mask\n",
    "\n",
    "                    f_data = np.ma.array(np.empty((len(y_dim),len(x_dim)), dtype=variable.datatype), mask=bool_mask, fill_value=fill_value)\n",
    "                    f_data =  np.where(f_data.mask, f_data, fill_value)\n",
    "                    f_data[bool_mask]=f_data1 \n",
    "                    \n",
    "                # Assign the interpolated data\n",
    "                    dst[name][...] = np.copy(f_data)\n",
    "                    \n",
    "                #print(\"o_data, f_data1, f_data, dst: max/min/sum\")  \n",
    "                #print(np.nanmax(o_data), np.nanmax(f_data1),np.nanmax(f_data[f_data != -9999]),np.nanmax(dst[name]))\n",
    "                #print(np.nanmin(o_data), np.nanmin(f_data1),np.nanmin(f_data[f_data != -9999]),np.nanmin(dst[name]))   \n",
    "                #print(np.nansum(o_data), np.nansum(f_data1),np.nansum(f_data[f_data != -9999]),np.nansum(dst[name]))  \n",
    "\n",
    "                count = count + 1\n",
    "\n",
    "            # Handle variables with three dimensions\n",
    "            if (len(variable.dimensions) == 3):\n",
    "                for index in range(variable.shape[0]):\n",
    "                    # get all the source data (global)\n",
    "                    source = src[name][index,:,:]\n",
    "                    o_data = source[points_in_daymet_land[4][:],points_in_daymet_land[5][:]]\n",
    "                    f_data1 = griddata(points, o_data, (grid_lat, grid_lon), method=iMethod)\n",
    "                    \n",
    "                    if (domain_type =='1'):\n",
    "                        # Assign the interpolated data\n",
    "                        dst[name][index,...] = np.copy(f_data1)\n",
    "                    else:\n",
    "\n",
    "                    # create a mask array to hold the interpolated data\n",
    "\n",
    "                        f_data = np.ma.array(np.empty((len(y_dim),len(x_dim)), dtype=variable.datatype), mask=bool_mask, fill_value=fill_value)\n",
    "                        f_data =  np.where(f_data.mask, f_data, fill_value)\n",
    "                        f_data[bool_mask]=f_data1 \n",
    "    \n",
    "                    # Assign the interpolated data to dst.variable\n",
    "                        dst[name][index,...] = np.copy(f_data)\n",
    "                        \n",
    "                    #print(\"o_data, f_data1, f_data, dst: max/min/sum\")  \n",
    "                    #print(np.nanmax(o_data), np.nanmax(f_data1),np.nanmax(f_data[f_data != -9999]),np.nanmax(dst[name][index,:,:]))\n",
    "                    #print(np.nanmin(o_data), np.nanmin(f_data1),np.nanmin(f_data[f_data != -9999]),np.nanmin(dst[name][index,:,:]))   \n",
    "                    #print(np.nansum(o_data), np.nansum(f_data1),np.nansum(f_data[f_data != -9999]),np.nansum(dst[name][index,:,:]))  \n",
    "\n",
    "                count = count + variable.shape[0]\n",
    "\n",
    "            # Handle variables with four dimensions\n",
    "            if (len(variable.dimensions) == 4):\n",
    "                for index1 in range(variable.shape[0]):\n",
    "                    for index2 in range(variable.shape[1]):\n",
    "                        # get all the source data (global)\n",
    "\n",
    "                        source = src[name][index1, index2,:, :]\n",
    "                        o_data = source[points_in_daymet_land[4][:],points_in_daymet_land[5][:]]\n",
    "                        \n",
    "                        f_data1 = griddata(points, o_data, (grid_lat, grid_lon), method=iMethod)                      \n",
    "                        if (domain_tpye == '1'):\n",
    "                            # Assign the interpolated data\n",
    "                            dst[name][index1,index2,...] = np.copy(f_data1)\n",
    "                        else:\n",
    "\n",
    "                        # create a mask array to hold the interpolated data\n",
    "                            f_data = np.ma.array(np.empty((len(y_dim),len(x_dim)), dtype=variable.datatype), mask=bool_mask, fill_value=fill_value)\n",
    "                            f_data =  np.where(f_data.mask, f_data, fill_value)\n",
    "                            f_data[bool_mask]=f_data1 \n",
    "    \n",
    "                        # Assign the interpolated data to dst.variable\n",
    "                            dst[name][index1,index2,...] = np.copy(f_data)\n",
    "\n",
    "                        #print(\"o_data, f_data1, f_data, dst: max/min/sum\")  \n",
    "                        #print(np.nanmax(o_data), np.nanmax(f_data1),np.nanmax(f_data[f_data != -9999]),np.nanmax(dst[name][index1,index2,:,:]))\n",
    "                        #print(np.nanmin(o_data), np.nanmin(f_data1),np.nanmin(f_data[f_data != -9999]),np.nanmin(dst[name][index1,index2,:,:]))   \n",
    "                        #print(np.nansum(o_data), np.nansum(f_data1),np.nansum(f_data[f_data != -9999]),np.nansum(dst[name][index1,index2,:,:]))  \n",
    "\n",
    "                    count = count + variable.shape[1]\n",
    "\n",
    "            end = process_time()\n",
    "            print(\"Generating variable: \" +name+ \" takes  {}\".format(end-start))\n",
    "\n",
    "        else:\n",
    "\n",
    "            # keep variables with the same dimension\n",
    "            xerr = dst.createVariable(name, variable.datatype, variable.dimensions)\n",
    "            # Copy variable attributes\n",
    "            dst[name].setncatts(src[name].__dict__)\n",
    "            # Copy the data\n",
    "\n",
    "            dst[name][...] = src[name][...]\n",
    "            \n",
    "            end = process_time()\n",
    "            print(\"Copying variable: \" +name+ \" takes  {}\".format(end-start))\n",
    "            \n",
    "        if count > 50:\n",
    "            dst.close()   # output the variable into a file to save memory\n",
    "\n",
    "            dst = nc.Dataset(output_file, 'a')\n",
    "\n",
    "            count = 0\n",
    "        \n",
    "        print(count)\n",
    "\n",
    "    # Close the files\n",
    "    src.close()\n",
    "    dst.close()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
